{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8012be7",
   "metadata": {},
   "source": [
    "# Web Scraping - Indeed.com\n",
    "General steps for Web Scraping\n",
    "1. Check whether the website allows web scraping\n",
    "2. Obtain the source code (HTML File) by using the website URL\n",
    "3. Download the website content\n",
    "4. Parse the content using keywords tags for elements of interest\n",
    "5. Extract relevant data/features\n",
    "6. Organize raw data in structured format (e.g., CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876b0ab",
   "metadata": {},
   "source": [
    "### Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20edefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096d6e0",
   "metadata": {},
   "source": [
    "### Path to webdriver (Firefox, Chrome) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ff706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the driver path is correct before running this script.\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "# Microsoft Windows\n",
    "\n",
    "driver_path = \"geckodriver.exe\"\n",
    "# Linux\n",
    "options = Options()\n",
    "options.binary_location = r'C:\\Program Files\\Mozilla Firefox\\firefox.exe'\n",
    "driver = webdriver.Firefox(executable_path=r'geckodriver.exe', options=options)\n",
    "#driver_path = \"./drivers/linux/geckodriver\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77187fd5",
   "metadata": {},
   "source": [
    "### Define position and location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2685a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enter a job position\n",
    "position = \"data analyst\"\n",
    "## Enter a location (City, State or Zip or remote)\n",
    "locations = \"remote\"\n",
    "\n",
    "def get_url(position, location):\n",
    "    url_template = \"https://www.indeed.com/jobs?q={}&l={}\"\n",
    "    url = url_template.format(position, location)\n",
    "    return url\n",
    "\n",
    "url = get_url(position, locations)\n",
    "dataframe = pd.DataFrame(columns=[\"Title\", \"Company\", \"Location\", \"Rating\", \"Date\", \"Salary\", \"Description\", \"Links\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308931c4",
   "metadata": {},
   "source": [
    "### Scrape job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115efb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job number    1 added - Senior Data Analyst\n",
      "Job number    2 added - Data Analyst, SQL\n",
      "Job number    3 added - Data Analyst\n",
      "Job number    4 added - Sr. Salesforce Business Analyst\n",
      "Job number    5 added - Lead Data Governance Analyst\n",
      "Job number    6 added - Junior Data Analyst\n",
      "Job number    7 added - Junior Data Analyst\n",
      "Job number    8 added - IT Business Analyst\n",
      "Job number    9 added - Data Analyst\n",
      "Job number   10 added - Analyst I, Data Science\n",
      "Job number   11 added - Data Analyst (Remote)\n",
      "Job number   12 added - Data Analyst I\n",
      "Job number   13 added - Data Analyst\n",
      "Job number   14 added - Health Care Data Analyst\n",
      "Job number   15 added - Business Intelligence Analyst 1 (Remote)\n",
      "Job number   16 added - Data Analyst\n",
      "Job number   17 added - Health Care Data Analyst\n",
      "Job number   18 added - Data Analyst\n",
      "Job number   19 added - Healthcare Data Analyst I (Contractor)\n",
      "Job number   20 added - HIM Data Integrity Analyst\n",
      "Job number   21 added - Data Analyst\n",
      "Job number   22 added - Population Health Visualization Data Analyst\n",
      "Job number   23 added - Jr. Data Analyst - Remote\n",
      "Job number   24 added - Data Analyst\n",
      "Job number   25 added - Data Analyst\n",
      "Job number   26 added - Customer Experience (CX) Analyst - Remote - WA, OR, ID, UT, AZ, NV, WY, AK, or TX\n",
      "Job number   27 added - Data Analyst, 100% Remote\n",
      "Job number   28 added - HR Business Intelligence (HRBI) Analyst\n",
      "Job number   29 added - Entry Level Business Analyst\n",
      "Job number   30 added - Data Reporting Analyst\n",
      "Job number   31 added - Remote Data Analyst\n",
      "Job number   32 added - Entry Level Business Analyst\n",
      "Job number   33 added - Healthcare Data Analyst\n",
      "Job number   34 added - Clinical Data Analyst\n",
      "Job number   35 added - Senior Data Analyst\n",
      "Job number   36 added - Data Analyst\n",
      "Job number   37 added - Data Analyst\n",
      "Job number   38 added - Data Analyst\n",
      "Job number   39 added - Data Analyst\n",
      "Job number   40 added - Reporting and Data Enablement Analyst (Remote)\n",
      "Job number   41 added - 100% REMOTE // SAS Data Analyst\n",
      "Job number   42 added - Healthcare Data Analyst\n",
      "Job number   43 added - Data Analyst\n",
      "Job number   44 added - Associate Research Data Analyst **REMOTE AVAILABLE**\n",
      "Job number   45 added - Sr. Business Data Analyst\n",
      "Job number   46 added - Data Analyst (Remote)\n",
      "Job number   47 added - Data Analyst - Remote\n",
      "Job number   48 added - Clinical Data Analyst\n",
      "Job number   49 added - IAM Business Analyst\n",
      "Job number   50 added - DEI and Onboarding Data Analyst\n",
      "Job number   51 added - Data Visualization Analyst (Remote)\n",
      "Job number   52 added - Data Analyst\n",
      "Job number   53 added - Junior Business Analyst\n",
      "Job number   54 added - Data Analyst\n",
      "Job number   55 added - Data Analyst (Remote)\n",
      "Job number   56 added - Data Analyst\n",
      "Job number   57 added - Sr. Business Data Analyst\n",
      "Job number   58 added - Data Analyst\n",
      "Job number   59 added - Business Analyst\n",
      "Job number   60 added - dbt Data Analyst\n",
      "Job number   61 added - Data Analyst\n",
      "Job number   62 added - Data Analyst\n",
      "Job number   63 added - Data Analyst, Supply Chain (Remote)\n",
      "Job number   64 added - IT - Data Analyst -8487-1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     18\u001B[0m links \u001B[38;5;241m=\u001B[39m liens[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_attribute(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhref\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     20\u001B[0m title \u001B[38;5;241m=\u001B[39m soup\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.jobTitle\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_text()\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[1;32m---> 21\u001B[0m company \u001B[38;5;241m=\u001B[39m \u001B[43msoup\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m.companyName\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mget_text()\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m     22\u001B[0m location \u001B[38;5;241m=\u001B[39m soup\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.companyLocation\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_text()\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## Number of postings to scrape\n",
    "postings = 100\n",
    "\n",
    "jn=0\n",
    "for i in range(0, postings, 10):\n",
    "    driver.get(url + \"&start=\" + str(i))\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    jobs = driver.find_elements(By.CLASS_NAME, 'job_seen_beacon')\n",
    "\n",
    "    for job in jobs:\n",
    "        result_html = job.get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(result_html, 'html.parser')\n",
    "        \n",
    "        jn += 1\n",
    "        \n",
    "        liens = job.find_elements(By.TAG_NAME, \"a\")\n",
    "        links = liens[0].get_attribute(\"href\")\n",
    "        \n",
    "        title = soup.select('.jobTitle')[0].get_text().strip()\n",
    "        company = soup.select('.companyName')[0].get_text().strip()\n",
    "        location = soup.select('.companyLocation')[0].get_text().strip()\n",
    "        try:\n",
    "            salary = soup.select('.salary-snippet-container')[0].get_text().strip()\n",
    "        except:\n",
    "            salary = 'NaN'\n",
    "        try:\n",
    "            rating = soup.select('.ratingNumber')[0].get_text().strip()\n",
    "        except:\n",
    "            rating = 'NaN'\n",
    "        try:\n",
    "            date = soup.select('.date')[0].get_text().strip()\n",
    "        except:\n",
    "            date = 'NaN'\n",
    "        try:\n",
    "            description = soup.select('.job-snippet')[0].get_text().strip()\n",
    "        except:\n",
    "            description = ''\n",
    "       \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{'Title': title,\n",
    "                                          \"Company\": company,\n",
    "                                          'Location': location,\n",
    "                                          'Rating': rating,\n",
    "                                          'Date': date,\n",
    "                                          \"Salary\": salary,\n",
    "                                          \"Description\": description,\n",
    "                                          \"Links\": links}])], ignore_index=True)\n",
    "        print(\"Job number {0:4d} added - {1:s}\".format(jn,title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3eb6e",
   "metadata": {},
   "source": [
    "### Scrape full job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Links_list = dataframe['Links'].tolist()\n",
    "#Links_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path=driver_path)\n",
    "descriptions=[]\n",
    "for i in Links_list:\n",
    "    driver.get(i)\n",
    "    driver.implicitly_wait(random.randint(3, 8))\n",
    "    jd = driver.find_element(By.XPATH, '//div[@id=\"jobDescriptionText\"]').text\n",
    "    descriptions.append(jd)\n",
    "    time.sleep(random.randint(5,10))\n",
    "\n",
    "dataframe['Descriptions'] = descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6ac4a",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4626f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a csv file\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "dataframe.to_csv(date + \"_\" + position + \"_\" + locations + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e98364",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
